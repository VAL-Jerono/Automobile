"""
PROJECT STRUCTURE & FILE INVENTORY
Insurance Risk Platform - Production ML/AI System
"""

# COMPLETE PROJECT TREE

automobile_claims/project_structure/
â”‚
â”œâ”€â”€ ğŸ“„ ROOT CONFIGURATION FILES
â”‚   â”œâ”€â”€ .env.example              [Environment variables template - 15 vars]
â”‚   â”œâ”€â”€ config.yaml               [Centralized configuration - 60+ settings]
â”‚   â”œâ”€â”€ requirements.txt           [Python dependencies - 60+ packages]
â”‚   â”œâ”€â”€ setup.sh                  [Linux/macOS auto-setup script]
â”‚   â””â”€â”€ setup.bat                 [Windows auto-setup script]
â”‚
â”œâ”€â”€ ğŸ“š DOCUMENTATION
â”‚   â”œâ”€â”€ README.md                 [800+ line architecture & setup guide]
â”‚   â”œâ”€â”€ IMPLEMENTATION_SUMMARY.md [Project status & progress tracking]
â”‚   â””â”€â”€ DEVELOPER_REFERENCE.md    [Quick commands & troubleshooting]
â”‚
â”œâ”€â”€ ğŸ“ DATA LAYER (MySQL + ETL)
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ scripts/
â”‚       â”‚   â”œâ”€â”€ init_db.py        [Database schema initialization]
â”‚       â”‚   â””â”€â”€ load_raw_data.py  [CSVâ†’MySQL ETL pipeline (105K rows)]
â”‚       â””â”€â”€ schemas/
â”‚           â””â”€â”€ mysql_schema.py   [8-table normalized schema definition]
â”‚
â”œâ”€â”€ ğŸ¤– ML LAYER (Models + RAG + LLM)
â”‚   â””â”€â”€ ml/
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â”œâ”€â”€ ensemble.py       [XGBoost+LightGBM+NN with SHAP]
â”‚       â”‚   â””â”€â”€ llm_fine_tune.py  [Ollama fine-tuning & generation]
â”‚       â”œâ”€â”€ rag/
â”‚       â”‚   â””â”€â”€ retrieval.py      [ChromaDB semantic search]
â”‚       â””â”€â”€ train_pipeline.py     [End-to-end training with MLflow]
â”‚
â”œâ”€â”€ ğŸŒ API LAYER (FastAPI)
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ main.py               [FastAPI app + lifecycle + middleware]
â”‚       â”œâ”€â”€ dependencies.py        [Model/RAG/LLM dependency injection]
â”‚       â””â”€â”€ routes/
â”‚           â”œâ”€â”€ predictions.py     [Lapse, claims, risk endpoints]
â”‚           â”œâ”€â”€ explanations.py    [SHAP + LLM narrative explanations]
â”‚           â”œâ”€â”€ rag.py             [Semantic search queries]
â”‚           â””â”€â”€ model_mgmt.py      [Model registry & drift checking]
â”‚
â”œâ”€â”€ ğŸ³ CONTAINERIZATION
â”‚   â””â”€â”€ docker/
â”‚       â”œâ”€â”€ Dockerfile.api        [FastAPI service image]
â”‚       â”œâ”€â”€ Dockerfile.ollama     [Ollama LLM service image]
â”‚       â””â”€â”€ docker-compose.yml    [6-service orchestration]
â”‚
â”œâ”€â”€ ğŸ“Š MONITORING
â”‚   â””â”€â”€ monitoring/
â”‚       â””â”€â”€ prometheus.yml        [Metrics scrape configuration]
â”‚
â”œâ”€â”€ âœ… TESTING
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ test_api.py           [11 API endpoint tests]
â”‚       â””â”€â”€ test_models.py        [ML model validation tests]
â”‚
â”œâ”€â”€ ğŸ”„ CI/CD WORKFLOWS
â”‚   â””â”€â”€ .github/workflows/
â”‚       â”œâ”€â”€ test.yml              [Unit tests + coverage + linting]
â”‚       â”œâ”€â”€ model_validation.yml  [Train + validate model AUC]
â”‚       â””â”€â”€ deploy.yml            [Docker build/push + deployment]
â”‚
â””â”€â”€ ğŸ“‹ PROJECT ARTIFACTS
    â””â”€â”€ docs/                     [Reserved for additional docs]


# FILE COUNT SUMMARY

âœ… COMPLETE PROJECT: 27 Files Total

Configuration Files:        5  (.env, config, requirements, setup scripts)
Documentation:              3  (README, SUMMARY, REFERENCE)
Data Layer:                 3  (schema, init, ETL loader)
ML Layer:                   4  (ensemble, LLM, RAG, training pipeline)
API Layer:                  6  (main, dependencies, 4 route modules)
Containerization:           3  (3 Docker files)
Monitoring:                 1  (Prometheus config)
Testing:                    2  (API tests, model tests)
CI/CD:                      3  (GitHub Actions workflows)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:                     30+ files
Total Size:                ~50 KB of production Python code


# LAYER-BY-LAYER BREAKDOWN

## LAYER 1: DATA (MySQL + ETL)
â”œâ”€ Database: 8-table normalized schema
â”‚  â”œâ”€ customers (customer_id, demographics, computed age)
â”‚  â”œâ”€ vehicles (vehicle_id, specs, computed vehicle_age)
â”‚  â”œâ”€ policies (policy_id, dates, target: Lapse)
â”‚  â”œâ”€ claims (claim_id, amounts, status)
â”‚  â”œâ”€ predictions (model outputs + confidence)
â”‚  â”œâ”€ feature_store (historical snapshots)
â”‚  â”œâ”€ audit_log (ETL tracking)
â”‚  â””â”€ indexes for query optimization
â”‚
â”œâ”€ ETL Pipeline: CSVâ†’MySQL
â”‚  â”œâ”€ Read Motor_vehicle_insurance_data.csv (105,555 rows, 30 columns)
â”‚  â”œâ”€ Parse dates (DD/MM/YYYY format handling)
â”‚  â”œâ”€ Deduplicate customers & vehicles
â”‚  â”œâ”€ Map relationships (policyâ†’customer, policyâ†’vehicle)
â”‚  â””â”€ Batch load with progress tracking (tqdm)
â”‚
â””â”€ Feature Engineering: Derived columns
   â”œâ”€ contract_days (date_start - date_lapse)
   â”œâ”€ age_at_start (age when policy started)
   â”œâ”€ licence_years (driving experience)
   â””â”€ vehicle_age (matriculation_year to now)

## LAYER 2: ML (Models + Interpretability)
â”œâ”€ Ensemble Classifier (Lapse/Risk Prediction)
â”‚  â”œâ”€ XGBoost component (n_estimators=100, depth=6)
â”‚  â”œâ”€ LightGBM component (n_estimators=100, leaves=31)
â”‚  â”œâ”€ Neural Network (3-layer with dropout: [128â†’64â†’32])
â”‚  â”œâ”€ Ensemble strategy: equal weighting (1/3 each)
â”‚  â”œâ”€ Output: Probability [0.0-1.0]
â”‚  â””â”€ Interpretability: SHAP TreeExplainer on XGBoost
â”‚
â”œâ”€ RAG System (Semantic Search)
â”‚  â”œâ”€ Embedding Model: all-MiniLM-L6-v2 (384-dim vectors)
â”‚  â”œâ”€ Vector DB: ChromaDB with cosine similarity
â”‚  â”œâ”€ Indexed Datasets: Policies + Claims history
â”‚  â”œâ”€ Query: Returns top-K similar documents
â”‚  â””â”€ Use Case: Find similar policies for recommendations
â”‚
â”œâ”€ Fine-tuned LLM (Ollama + LoRA)
â”‚  â”œâ”€ Base Model: llama2 (quantized Q4_K_M)
â”‚  â”œâ”€ Fine-tuning: LoRA (rank=8, alpha=16)
â”‚  â”œâ”€ Tasks:
â”‚  â”‚  â”œâ”€ generate_claim_explanation()
â”‚  â”‚  â”œâ”€ generate_policy_recommendation()
â”‚  â”‚  â”œâ”€ generate_risk_assessment()
â”‚  â”‚  â””â”€ batch_generate_explanations()
â”‚  â””â”€ Inference: HTTP API to Ollama service
â”‚
â””â”€ Training Pipeline (MLflow Integration)
   â”œâ”€ Data loading (from CSV with 80/10/10 split)
   â”œâ”€ Preprocessing (encoding, scaling, imputation)
   â”œâ”€ Model training (with validation monitoring)
   â”œâ”€ Cross-validation (5-fold stratified)
   â”œâ”€ Metrics logging (accuracy, precision, recall, F1, AUC)
   â””â”€ Model persistence (joblib + HDF5)

## LAYER 3: API (FastAPI REST)
â”œâ”€ Core Application (main.py)
â”‚  â”œâ”€ FastAPI initialization with lifespan management
â”‚  â”œâ”€ CORS middleware for cross-origin requests
â”‚  â”œâ”€ Health check endpoints
â”‚  â”œâ”€ Auto-generated documentation (Swagger UI + ReDoc)
â”‚  â””â”€ Error handling & logging
â”‚
â”œâ”€ Route: Predictions (/api/v1/predict/*)
â”‚  â”œâ”€ POST /lapse
â”‚  â”‚  â”œâ”€ Input: PolicyData (age, vehicle_age, premium, claims, fuel_type)
â”‚  â”‚  â””â”€ Output: Probability, risk_level (Low/Medium/High), action
â”‚  â”œâ”€ POST /risk_score
â”‚  â”‚  â”œâ”€ Input: PolicyData
â”‚  â”‚  â””â”€ Output: 0-100 score, category, factors, mitigation strategies
â”‚  â””â”€ POST /claims_amount
â”‚     â”œâ”€ Input: ClaimsData
â”‚     â””â”€ Output: Expected amount, frequency, severity
â”‚
â”œâ”€ Route: Explanations (/api/v1/explain/*)
â”‚  â”œâ”€ POST /prediction
â”‚  â”‚  â”œâ”€ Input: ExplanationRequest (prediction_id, include_llm)
â”‚  â”‚  â””â”€ Output: Top features (SHAP), narrative
â”‚  â””â”€ POST /narrative
â”‚     â”œâ”€ Input: PredictionNarrativeRequest
â”‚     â””â”€ Output: LLM-generated explanation, insights, next steps
â”‚
â”œâ”€ Route: RAG (/api/v1/rag/*)
â”‚  â”œâ”€ POST /query
â”‚  â”‚  â”œâ”€ Input: Query text, type (policy|claims), top_k
â”‚  â”‚  â””â”€ Output: Ranked results with similarity scores
â”‚  â””â”€ POST /recommendations
â”‚     â”œâ”€ Input: PolicyId, context
â”‚     â””â”€ Output: Personalized recommendations + evidence
â”‚
â”œâ”€ Route: Model Management (/api/v1/models/*)
â”‚  â”œâ”€ GET /info
â”‚  â”‚  â””â”€ Output: List[ModelInfo] (name, version, accuracy, AUC)
â”‚  â”œâ”€ POST /retrain
â”‚  â”‚  â”œâ”€ Input: ModelName, date_range
â”‚  â”‚  â””â”€ Output: Task ID, status, ETA
â”‚  â””â”€ GET /drift_check
â”‚     â””â”€ Output: Drift detected, score, affected features
â”‚
â””â”€ Dependencies (dependency_injection.py)
   â”œâ”€ Lazy loading of models
   â”œâ”€ Model instance caching
   â”œâ”€ Error handling for missing services

## LAYER 4: MONITORING & OBSERVABILITY
â”œâ”€ MLflow (Experiment Tracking)
â”‚  â”œâ”€ Runs: Parameters, metrics, artifacts
â”‚  â”œâ”€ Model Registry: Versioning, staging, production
â”‚  â”œâ”€ Backend: MySQL (persistent)
â”‚  â””â”€ UI: http://localhost:5000
â”‚
â”œâ”€ Prometheus (Metrics Collection)
â”‚  â”œâ”€ Scrape Targets: API, Ollama, MySQL, MLflow
â”‚  â”œâ”€ Metrics:
â”‚  â”‚  â”œâ”€ api_requests_total (count, latency)
â”‚  â”‚  â”œâ”€ model_predictions_counter
â”‚  â”‚  â”œâ”€ data_drift_score
â”‚  â”‚  â””â”€ custom business metrics
â”‚  â””â”€ Retention: 15 days default
â”‚
â”œâ”€ Grafana (Dashboards)
â”‚  â”œâ”€ Model Performance: AUC, accuracy, precision, recall
â”‚  â”œâ”€ API Health: Latency, error rate, throughput
â”‚  â”œâ”€ Data Drift: Feature distributions vs baseline
â”‚  â”œâ”€ Database: Query performance, connection pool
â”‚  â””â”€ UI: http://localhost:3000 (admin/admin)
â”‚
â””â”€ Drift Detection (Evidently)
   â”œâ”€ Feature Distribution: KS-test (p-value threshold 0.05)
   â”œâ”€ Target Distribution: Chi-square for categoricals
   â”œâ”€ Triggers: Retraining if drift detected
   â””â”€ Alerting: Slack/Email notifications


# CONFIGURATION HIERARCHY

config.yaml (centralized settings)
  â”œâ”€ project metadata (name, version, description)
  â”œâ”€ data paths & parameters (CSV, target, split ratios)
  â”œâ”€ database settings (MySQL connection params)
  â”œâ”€ ml.ensemble (XGBoost, LightGBM, NN hyperparams)
  â”œâ”€ ml.rag (embedding model, similarity threshold)
  â”œâ”€ ml.llm (Ollama config, LoRA fine-tuning params)
  â”œâ”€ api (host, port, debug mode, workers)
  â””â”€ monitoring (MLflow, Prometheus, drift detection thresholds)

.env (runtime secrets - NOT in git)
  â”œâ”€ MySQL credentials
  â”œâ”€ Ollama host
  â”œâ”€ MLflow tracking URI
  â”œâ”€ API port & debug mode
  â””â”€ Directory paths

requirements.txt (Python dependencies - 60+ packages)
  â”œâ”€ Core ML: pandas, numpy, scikit-learn
  â”œâ”€ Models: xgboost, lightgbm, tensorflow, transformers
  â”œâ”€ Vector DB: chromadb, sentence-transformers
  â”œâ”€ API: fastapi, uvicorn, pydantic
  â”œâ”€ Database: mysql-connector-python, sqlalchemy
  â”œâ”€ Orchestration: apache-airflow
  â”œâ”€ Monitoring: mlflow, prometheus-client
  â””â”€ Dev: pytest, black, flake8, mypy


# DEPLOYMENT STACK

Services in docker-compose.yml:
1. mysql:8.0               (Database - port 3306)
2. insurance-api           (FastAPI - port 8000)
3. ollama:latest           (LLM - port 11434)
4. mlflow:latest           (Experiment Tracking - port 5000)
5. prometheus:latest       (Metrics - port 9090)
6. grafana:latest          (Dashboards - port 3000)

Volumes:
- mysql_data               (MySQL persistence)
- ollama_data              (Model cache)
- mlflow_artifacts         (Experiment artifacts)
- prometheus_data          (Metrics storage)
- grafana_data             (Dashboard configs)

Networks:
- insurance_network        (Inter-service communication)


# CONTINUOUS INTEGRATION & DEPLOYMENT

GitHub Actions Workflows:
1. test.yml
   â”œâ”€ Trigger: Push/PR to main/develop
   â”œâ”€ Matrix: Python 3.9, 3.10, 3.11
   â”œâ”€ Steps: Lint (flake8), format (black), type check (mypy)
   â”œâ”€ Tests: pytest with coverage reporting
   â””â”€ Gate: Coverage â‰¥80%

2. model_validation.yml
   â”œâ”€ Trigger: Push to main (ML files changed)
   â”œâ”€ MySQL: Service container for testing
   â”œâ”€ Steps: Init DB â†’ Load data â†’ Train â†’ Validate AUC
   â””â”€ Gate: AUC â‰¥0.75 (blocks merge if failed)

3. deploy.yml
   â”œâ”€ Trigger: Version tags (v*.*)
   â”œâ”€ Steps: Docker build â†’ push to registry â†’ deploy staging
   â”œâ”€ Health checks: Wait for API readiness
   â”œâ”€ Smoke tests: Sample predictions + explanations
   â””â”€ Notifications: Success/failure alerts


# TESTING COVERAGE

Unit Tests (pytest):
1. test_api.py (11 tests)
   â”œâ”€ Health check endpoint
   â”œâ”€ Prediction endpoints (valid/invalid inputs)
   â”œâ”€ Explanation generation
   â”œâ”€ RAG queries
   â”œâ”€ Model management endpoints
   â””â”€ Error handling & validation

2. test_models.py (5+ tests)
   â”œâ”€ Model initialization
   â”œâ”€ Train/predict workflow
   â”œâ”€ Explanation generation
   â”œâ”€ Feature engineering
   â””â”€ Preprocessing pipeline

Coverage Target: â‰¥80% of ml/ and api/ modules


# QUICK REFERENCE

## Commands
setup.sh / setup.bat         Auto-setup with venv + deps
python data/scripts/init_db.py     Initialize MySQL schema
python data/scripts/load_raw_data.py   Load 105K rows from CSV
python ml/train_pipeline.py     Train ensemble with MLflow logging
uvicorn api.main:app --reload   Start API (dev mode)
pytest tests/ -v                Run all tests
docker-compose up -d            Start full stack

## Endpoints (when API running)
http://localhost:8000           API root
http://localhost:8000/docs      Swagger UI (interactive testing)
http://localhost:5000           MLflow tracking server
http://localhost:9090           Prometheus metrics
http://localhost:3000           Grafana dashboards

## Performance Targets
- API latency: <500ms for predictions
- Model AUC: â‰¥0.75
- Code coverage: â‰¥80%
- Test execution: <60 seconds
- Data drift threshold: KS-test p-value > 0.05


# STATUS INDICATORS

âœ… Complete & Ready:
  - Project structure & configuration
  - Data layer (MySQL schema + ETL)
  - ML models (ensemble, RAG, LLM interface)
  - API layer (6 route modules)
  - Docker containerization
  - Testing suite
  - CI/CD workflows
  - Documentation

ğŸ”„ In Progress:
  - Monitoring integration (Prometheus â†’ API metrics)
  - MLflow integration in training pipeline
  - Grafana dashboard creation

â³ Planned:
  - Airflow DAG for data orchestration
  - Feature store pipeline
  - Drift detection rules & alerting
  - Production Kubernetes deployment

---

Generated: 2024-12-15
Project Status: MVP Ready (foundation complete, integration pending)
